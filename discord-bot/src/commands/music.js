// discord-bot/src/commands/music.js
import { SlashCommandBuilder } from 'discord.js';
import { 
    joinVoiceChannel, 
    createAudioPlayer, 
    createAudioResource, 
    entersState, 
    StreamType, 
    AudioPlayerStatus,
    VoiceConnectionStatus 
} from '@discordjs/voice';
// import { PassThrough } from 'stream'; // Para criar um stream de √°udio

// URL da API Backend (substituir por vari√°vel de ambiente)
const BACKEND_API_URL = process.env.NAKAMA_BACKEND_URL || 'http://localhost:3000/api';
const BOT_API_KEY = process.env.NAKAMA_BOT_API_KEY || 'supersecretbotapikey'; // Chave para autenticar com o backend

// Mock/Placeholder para obter o stream de √°udio do backend
// Em uma implementa√ß√£o real, isso se conectaria ao backend (ex: via WebSocket ou um endpoint que retorna um stream)
async function getAudioStreamFromBackend(sessionId, guildId, interaction) {
    // Esta fun√ß√£o precisa ser robusta.
    // 1. Chamar o backend /api/bot/connect para validar a sess√£o e informar que o bot est√° pronto.
    // 2. Se sucesso, o backend deve prover uma forma de obter o √°udio.
    //    Pode ser um WebSocket que o bot se conecta, ou o backend come√ßa a enviar dados.

    try {
        const connectResponse = await fetch(`${BACKEND_API_URL}/bot/connect`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-Bot-Api-Key': BOT_API_KEY, // Autentica√ß√£o do bot com o backend
            },
            body: JSON.stringify({
                session_id: sessionId,
                discord_user_id: interaction.user.id,
                guild_id: guildId,
                voice_channel_id: interaction.member.voice.channel.id,
            }),
        });

        if (!connectResponse.ok) {
            const errorData = await connectResponse.json();
            console.error(`[MusicCmd] Falha ao conectar com backend para sess√£o ${sessionId}:`, errorData);
            await interaction.followUp({ content: `Erro ao conectar com o servidor Nakama: ${errorData.error || 'Erro desconhecido.'}`, ephemeral: true });
            return null;
        }

        const connectData = await connectResponse.json();
        console.log(`[MusicCmd] Conex√£o com backend para sess√£o ${sessionId} estabelecida:`, connectData.message);

        // Agora, como obter o √°udio?
        // Op√ß√£o A: Backend retorna um endpoint WebSocket para o bot se conectar.
        // Op√ß√£o B: Esta chamada /bot/connect j√° "ativa" o envio de √°udio do backend para o bot (menos comum para √°udio cont√≠nuo).
        // Op√ß√£o C: O backend exp√µe uma fun√ß√£o (se no mesmo processo, o que n√£o √© o caso aqui) ou um mecanismo de pub/sub (Redis).

        // Para este placeholder, vamos assumir que o backend agora sabe para onde enviar o √°udio
        // e o bot precisa apenas de um stream local para o AudioPlayer.
        // A l√≥gica de como o backend envia os dados para este bot (ex: via um WebSocket que o bot abre para o backend,
        // ou o backend abre uma conex√£o para o bot) precisa ser definida.
        
        // Placeholder: Simular um stream que receberia dados do backend.
        // const audioPassThrough = new PassThrough();
        
        // O backend (via fastify.getAudioStreamForSession) precisaria de uma forma de "empurrar" dados para este bot.
        // Isso √© complexo entre processos. Uma solu√ß√£o seria o bot abrir um WS para o backend e receber os chunks.
        // fastify.getAudioStreamForSession(sessionId) no backend √© um bom come√ßo, mas como o bot o chama e recebe dados?

        // Simplifica√ß√£o para o placeholder:
        // Vamos assumir que o backend tem uma forma de enviar os dados para o bot
        // e o bot os recebe e os coloca em um stream que o AudioPlayer pode consumir.
        // Esta parte √© a mais cr√≠tica e depende da arquitetura de comunica√ß√£o backend <-> bot.
        
        // Exemplo: se o backend fosse expor um stream HTTP (n√£o ideal para tempo real, mas para exemplo)
        // const audioResponse = await fetch(`${BACKEND_API_URL}/audio/stream/${sessionId}`);
        // return audioResponse.body; // Retorna um ReadableStream (Node.js stream)
        
        // Por enquanto, retornamos um placeholder que precisa ser conectado √† fonte real de √°udio.
        // O AudioPlayer espera um Readable, ent√£o vamos criar um PassThrough que precisaria ser alimentado.
        // const stream = new PassThrough();
        // console.log(`[MusicCmd] Stream PassThrough criado para sess√£o ${sessionId}. Aguardando dados do backend...`);
        // TODO: Implementar a l√≥gica de recebimento de dados do backend e escrita no 'stream'.
        // Exemplo: se o bot se conecta a um WebSocket do backend para receber os chunks de √°udio:
        // const audioWs = new WebSocket(`${BACKEND_WS_URL}/ws/audio/subscribe/${sessionId}`);
        // audioWs.on('message', (chunk) => stream.write(chunk));
        // audioWs.on('close', () => stream.end());
        // return stream;

        // Para este esqueleto, vamos apenas logar e retornar null, indicando que a l√≥gica de streaming real falta.
        console.log(`[MusicCmd] L√≥gica de obten√ß√£o de stream de √°udio para sess√£o ${sessionId} do backend precisa ser implementada.`);
        await interaction.followUp({ content: `Conectado ao backend, mas a parte de streaming de √°udio ainda √© um placeholder.`, ephemeral: true });
        return null; // Retornar null at√© que a l√≥gica de streaming esteja implementada

    } catch (error) {
        console.error(`[MusicCmd] Erro cr√≠tico ao tentar obter stream de √°udio para ${sessionId}:`, error);
        await interaction.followUp({ content: `Erro cr√≠tico ao comunicar com o servidor Nakama. Tente novamente mais tarde.`, ephemeral: true });
        return null;
    }
}


export default {
  data: new SlashCommandBuilder()
    .setName('music')
    .setDescription('Conecta o bot ao seu canal de voz para tocar o √°udio da sess√£o Nakama.')
    .addStringOption(option =>
      option.setName('id_sessao')
        .setDescription('O ID da sua sess√£o Nakama (vis√≠vel no dashboard).')
        .setRequired(true)),
  async execute(interaction, client) {
    const sessionId = interaction.options.getString('id_sessao');

    // Verificar se o usu√°rio est√° em um canal de voz
    const voiceChannel = interaction.member?.voice?.channel;
    if (!voiceChannel) {
      return interaction.reply({ content: 'Voc√™ precisa estar em um canal de voz para usar este comando!', ephemeral: true });
    }

    // Verificar permiss√µes do bot para conectar e falar
    const permissions = voiceChannel.permissionsFor(client.user);
    if (!permissions.has('CONNECT')) {
      return interaction.reply({ content: 'N√£o tenho permiss√£o para conectar a este canal de voz!', ephemeral: true });
    }
    if (!permissions.has('SPEAK')) {
      return interaction.reply({ content: 'N√£o tenho permiss√£o para falar neste canal de voz!', ephemeral: true });
    }

    await interaction.deferReply(); // Adiar a resposta, pois pode levar tempo

    try {
      // 1. Obter o stream de √°udio do backend (Placeholder)
      const audioStream = await getAudioStreamFromBackend(sessionId, interaction.guildId, interaction);

      if (!audioStream) {
        // getAudioStreamFromBackend j√° deve ter enviado uma mensagem de erro.
        // Se n√£o, descomente:
        // await interaction.followUp({ content: `N√£o foi poss√≠vel obter o stream de √°udio para a sess√£o ${sessionId}. Verifique o ID ou tente novamente.`, ephemeral: true });
        return;
      }

      // 2. Conectar ao canal de voz
      const connection = joinVoiceChannel({
        channelId: voiceChannel.id,
        guildId: interaction.guildId,
        adapterCreator: interaction.guild.voiceAdapterCreator,
        selfDeaf: true, // O bot se ensurdece para n√£o gastar recursos processando seu pr√≥prio √°udio
      });

      // Lidar com estados da conex√£o de voz
      connection.on(VoiceConnectionStatus.Disconnected, async (oldState, newState) => {
        try {
            await Promise.race([
                entersState(connection, VoiceConnectionStatus.Signalling, 5_000),
                entersState(connection, VoiceConnectionStatus.Connecting, 5_000),
            ]);
            // Parece ser uma desconex√£o tempor√°ria, reconectando...
        } catch (error) {
            // Parece ser uma desconex√£o real, destruir a conex√£o.
            if (connection.state.status !== VoiceConnectionStatus.Destroyed) {
                connection.destroy();
            }
            console.log(`[MusicCmd] Conex√£o de voz para sess√£o ${sessionId} desconectada e destru√≠da.`);
            // TODO: Notificar o backend que o bot desconectou?
        }
      });
      
      connection.on(VoiceConnectionStatus.Destroyed, () => {
        console.log(`[MusicCmd] Conex√£o de voz para ${sessionId} destru√≠da.`);
        // Limpar player, etc.
        player.stop();
      });

      await entersState(connection, VoiceConnectionStatus.Ready, 30_000); // Esperar at√© 30s para conectar
      console.log(`[MusicCmd] Conectado ao canal de voz ${voiceChannel.name} para sess√£o ${sessionId}.`);

      // 3. Criar AudioPlayer e AudioResource
      const player = createAudioPlayer();
      
      // O tipo de stream (Opus, PCM) deve ser conhecido ou negociado com o backend.
      // Para node-portaudio ou ffmpeg, pode ser PCM. Se Opus, melhor ainda.
      const resource = createAudioResource(audioStream, {
        inputType: StreamType.Arbitrary, // Usar StreamType.Opus ou StreamType.Raw (PCM) se souber o formato
        // inlineVolume: true, // Se quiser controlar o volume por usu√°rio (requer processamento)
      });

      player.play(resource);
      await entersState(player, AudioPlayerStatus.Playing, 10_000); // Esperar at√© 10s para come√ßar a tocar
      console.log(`[MusicCmd] Reprodu√ß√£o iniciada para sess√£o ${sessionId}.`);

      // 4. Inscrever a conex√£o de voz no player
      const subscription = connection.subscribe(player);

      // Lidar com o fim da reprodu√ß√£o ou erros
      player.on(AudioPlayerStatus.Idle, () => {
        console.log(`[MusicCmd] Player ficou Idle para sess√£o ${sessionId}. Stream terminou ou foi interrompido.`);
        if (connection.state.status !== VoiceConnectionStatus.Destroyed) {
            connection.destroy(); // Desconectar do canal de voz
        }
        // O stream de √°udio (audioStream) deve ser fechado/finalizado pela fonte (backend ou getAudioStreamFromBackend)
      });

      player.on('error', error => {
        console.error(`[MusicCmd] Erro no AudioPlayer para sess√£o ${sessionId}:`, error.message);
        if (connection.state.status !== VoiceConnectionStatus.Destroyed) {
            connection.destroy();
        }
        // Tentar notificar o usu√°rio sobre o erro
        interaction.followUp({ content: `Ocorreu um erro durante a reprodu√ß√£o: ${error.message}`, ephemeral: true }).catch(console.error);
      });
      
      await interaction.followUp({ content: `üé∂ Conectado e pronto para tocar o √°udio da sess√£o \`${sessionId}\`!`, ephemeral: false });

      // Manter a intera√ß√£o viva ou fornecer controles (pausar, parar) - Fora do escopo deste placeholder inicial.
      // Ex: coletor de bot√µes para pausar/parar.
      // O bot desconectar√° quando o stream terminar (player idle) ou se houver erro.

    } catch (error) {
      console.error(`[MusicCmd] Erro geral no comando /music para sess√£o ${sessionId}:`, error);
      await interaction.followUp({ content: 'Ocorreu um erro inesperado ao tentar tocar o √°udio.', ephemeral: true });
      // Tentar limpar conex√µes se existirem e n√£o foram destru√≠das
      // (precisaria de acesso √† `connection` e `player` aqui, o que pode ser complicado com escopo de try/catch)
    }
  },
};
